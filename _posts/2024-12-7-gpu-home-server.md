---
layout: post
title:  "GPU home server"
lang: en
tags: [en, gpu, server, cuda, nvidia, p40]
published: true
---

How to build a minimalistic GPU server with 24GB VRAM for running inference and training using modern CUDA.

## My video on Youtube

<iframe width="560" height="315" src="https://www.youtube.com/embed/dfDnEBk9l6s?si=CD9Eh8eq3QQYKM3r" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

## Github repo

[GPU home server](https://github.com/placebeyondtheclouds/gpu-home-server)